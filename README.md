# latentgee
Pseudo-batch estimation in latent space with GEE-based residualization for batch effect removal.

ì¢‹ì•„ ğŸ‘
ë…¼ë¬¸ ì œì¶œ + GitHub ê³µê°œ + ë‚´ë¶€ ë°°í¬ê¹Œì§€ ëª¨ë‘ ì»¤ë²„ë˜ëŠ” **ì—°êµ¬ìš© íŒ¨í‚¤ì§€ README í…œí”Œë¦¿**ì„ ê¹”ë”í•˜ê²Œ ì‘ì„±í•´ì¤„ê²Œ.
(ê³¼ì¥ ì—†ì´, ì¬í˜„ì„± ê°•ì¡°, ë¦¬ë·°ì–´ ì¹œí™”ì  í†¤ìœ¼ë¡œ êµ¬ì„±)

---

# ğŸ“„ README.md í…œí”Œë¦¿

ì•„ë˜ ê·¸ëŒ€ë¡œ ë³µë¶™í•´ì„œ ì‹œì‘í•´ë„ ë˜ê³ , ì´ë¦„ë§Œ ë°”ê¿”ë„ ë¼.

---

# LatentGEE

**Unsupervised latent-space batch effect correction via VAE and GEE residualization.**

LatentGEE is a Python framework for detecting and correcting batch effects in high-dimensional biological data.
It combines:

* Variational Autoencoders (VAE) for latent representation learning
* Unsupervised pseudo-batch estimation in latent space
* Generalized Estimating Equations (GEE) for residual-based batch correction

The method is designed for settings where true batch labels are partially known or unknown.

---

## ğŸ”¬ Method Overview

The correction pipeline consists of:

1. Learn latent representation using a VAE
2. Estimate pseudo-batch structure via clustering in latent space
3. Fit a GEE model using pseudo-batch (and optional clinical covariates)
4. Remove only the pseudo-batch component
5. Decode corrected latent representation back to data space

This approach allows preservation of biological signal while reducing unwanted batch variation.

---

## ğŸ“¦ Installation

### 1. Clone repository

```bash
git clone https://github.com/<your-username>/LatentGEE.git
cd LatentGEE
```

### 2. Create virtual environment

```bash
python -m venv venv
source venv/bin/activate      # Windows: venv\Scripts\activate
pip install -r requirements.txt
```

---

## ğŸš€ Quick Start

Minimal example:

```python
import numpy as np
from latentgee.pipeline.runner import LatentGEEPipeline
from latentgee.config.schema import ModelConfig, TrainConfig, EvalConfig

X = np.random.rand(200, 100)

model_cfg = ModelConfig(input_dim=100)
train_cfg = TrainConfig(epochs=50)
eval_cfg = EvalConfig()

pipeline = LatentGEEPipeline(X, model_cfg, train_cfg, eval_cfg)

pipeline.fit()
results = pipeline.evaluate()

X_corrected = pipeline.correct_and_decode()
```

---

## âš™ï¸ Configuration

Experiments are controlled via `config.yaml`.

Example:

```yaml
seed: 42

data:
  zero_prevalence_cutoff: 0.1
  standardize_latent: true

training:
  epochs: 100
  batch_size: 256
  learning_rate: 1e-3
```

To run an experiment:

```bash
python experiments/run_scene2.py --config config.yaml
```

---

## ğŸ” Reproducibility

All experiments should specify:

* Python version
* PyTorch version
* CUDA version (if applicable)
* Random seed

To ensure deterministic behavior:

```python
from latentgee.utils.seed import set_seed
set_seed(42)
```

The repository has been tested with:

* Python 3.10
* Torch 2.1.0
* CUDA 12.1

Dependencies are listed in `requirements.txt`.

---

## ğŸ’¾ Model Saving & Loading

```python
from latentgee.pipeline.checkpoint import save_model, load_model

save_model(model, "model.pt")

model = load_model(model, "model.pt")
```

Saved checkpoints include:

* model state_dict
* configuration
* training parameters
* seed

---

## ğŸ“Š Evaluation Metrics

LatentGEE supports:

* Silhouette score
* PERMANOVA RÂ²
* Before/after batch comparison
* Biological signal preservation analysis

---

## ğŸ“ Repository Structure

```
latentgee/
    core/        # Model definitions and statistical methods
    pipeline/    # Training and execution orchestration
    config/      # Configuration schemas
experiments/     # Reproducible experiment scripts
```

---

## ğŸ“š Citation

If you use this repository in your research, please cite:

```
<To be updated after publication>
```

---

## ğŸ§ª Development Status

This repository is currently research-focused and under active development.
Interface changes may occur before first stable release.

---

## ğŸ“ License

Specify license here (e.g., MIT License).

---

## ğŸ¤ Contact

For questions or collaboration:

*  Name
*  Institution
*  Email




ğŸ”¥ ê°€ì¥ ì¤‘ìš”í•œ ì„¤ê³„ ì›ì¹™

coreëŠ” ì ˆëŒ€ pipelineì„ ëª°ë¼ì•¼ í•œë‹¤.
coreì˜ ì—­í• ì€: ì•Œê³ ë¦¬ì¦˜ ê·¸ ìì²´ (VAE, loss í•¨ìˆ˜, GEE residual, clustering, metric,... ëª¨ë¸ ì •ì˜ì™€ ìˆ˜í•™ì  ì—°ì‚°!)
pipelineì€ coreë¥¼ importí•´ë„ ë˜ì§€ë§Œ
coreê°€ pipelineì„ importí•˜ë©´ êµ¬ì¡°ê°€ ë¬´ë„ˆì§„ë‹¤.

ğŸ” íŒë‹¨ ê¸°ì¤€ í•˜ë‚˜ë§Œ ê¸°ì–µí•´

ì´ ì§ˆë¬¸ì„ ë˜ì ¸ë´:

ì´ ì½”ë“œëŠ” ëª¨ë¸ì˜ ë³¸ì§ˆì¸ê°€,
ì•„ë‹ˆë©´ ëª¨ë¸ì„ ì–´ë–»ê²Œ ëŒë¦´ì§€ì— ëŒ€í•œ ì „ëµì¸ê°€?

core/        â† ë³¸ì§ˆ/ ì•Œê³ ë¦¬ì¦˜ (VAE, GEE, clustering)
    â†‘
pipeline/    â† ì‹¤í–‰ orchestration/ì‹¤í–‰ ì „ëµ 
    â†‘
cli.py       â† ì—”íŠ¸ë¦¬ í¬ì¸íŠ¸

ğŸ“¦ ê°€ì¥ ì´ìƒì ì¸ êµ¬ì¡°
core/
    [v]networks.py   â† FlexibleMLP
    [v]vae.py        â† VAEë§Œ
    [v]losses.py
    [v]gee.py
    [ ]clustering.py
    [ ]evaluation.py
config/
    [v]schema.py        â† dataclass ì •ì˜
    [ ]loader.py        â† yaml â†’ dataclass ë§¤í•‘
    [v]searchspace.py   â† optuna suggest ë¡œì§
pipeline/ # "í•™ìŠµ ì‹¤í–‰ ì „ëµ (training orchestration)"
    trainer.py      â† LatentGEEModule ì—¬ê¸°
    corrector.py
    evaluator.py
    [v]runner.py       <-- LatentGEEPipeline
    [v]checkpoint.py
    tuner.py


ğŸ¯ 3ï¸âƒ£ ë…¼ë¬¸ supplementary ê´€ì ì—ì„œ ì¤‘ìš”í•œ ê²ƒ

ë¦¬ë·°ì–´ê°€ ë³´ëŠ” ê±´ 3ê°€ì§€ì•¼:

â‘  ì¬í˜„ ê°€ëŠ¥ì„±

config.yaml í¬í•¨

random seed ê³ ì •

requirements.txt í¬í•¨

â‘¡ êµ¬ì¡°ì˜ ëª…í™•ì„±

core / pipeline ë¶„ë¦¬

í•¨ìˆ˜ docstring ì¶©ë¶„íˆ ì‘ì„±

â‘¢ ì‹¤í–‰ ì˜ˆì œ ì œê³µ
experiments/run_example.py
ì´ íŒŒì¼ì´ ì •ë§ ì¤‘ìš”í•¨.

ğŸ¯ 5ï¸âƒ£ ê°€ì¥ í˜„ì‹¤ì ì¸ ë¡œë“œë§µ

ì§€ê¸ˆ:

GitHub + ë…¼ë¬¸ supplementaryìš© clean repo ë§Œë“¤ê¸°

ë…¼ë¬¸ accept í›„:

pip ë°°í¬

ì´ê²Œ ìì—°ìŠ¤ëŸ¬ìš´ ìˆœì„œì•¼.

ğŸ¯ 6ï¸âƒ£ ê·¸ëŸ¼ ì§€ê¸ˆ ë‹¹ì¥ ê¼­ í•´ì•¼ í•  ê²ƒ

âœ” sys.path.append ì œê±°
âœ” requirements.txt ì‘ì„±
âœ” READMEì— ìµœì†Œ ì‹¤í–‰ ì˜ˆì‹œ ì¶”ê°€
âœ” seed ê³ ì • ì˜µì…˜ ì¶”ê°€
âœ” ëª¨ë¸ ì €ì¥/ë¡œë“œ êµ¬ì¡° ì •ë¦¬